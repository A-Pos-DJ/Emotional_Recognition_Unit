{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvModelTrainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iB-sYuJaumh",
        "colab_type": "code",
        "outputId": "afe2d696-0034-4acd-e6c8-d7ecc3d438e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Check to see if we need to install EmoPy\n",
        "import sys\n",
        "\n",
        "if not 'EmoPy' in sys.modules:\n",
        "  print(\"Installing EmoPy...\")\n",
        "  !pip install Keras==2.2.4\n",
        "  !pip install scipy==1.1.0\n",
        "  !pip install EmoPy\n",
        "else:\n",
        "  print(\"EmoPy has already been installed...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing EmoPy...\n",
            "Collecting Keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4) (1.17.5)\n",
            "Installing collected packages: Keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed Keras-2.2.4\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 99kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.17.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.1.0\n",
            "Collecting EmoPy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/36/3c33149c382fb549c29a255cdbeca59c15bb1fa39d8a321836acb3a4c056/EmoPy-0.0.5-py3-none-any.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 208kB/s \n",
            "\u001b[?25hCollecting lasagne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/bf/4b2336e4dbc8c8859c4dd81b1cff18eef2066b4973a1bd2b0ca2e5435f35/Lasagne-0.1.tar.gz (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 61.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from EmoPy) (2.8.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (0.22.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from EmoPy) (4.1.2.30)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from EmoPy) (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (1.1.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from EmoPy) (3.6.4)\n",
            "Collecting numpy<=1.14.5,>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=1.10.1 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (1.15.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from EmoPy) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>2.1.0 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (3.1.3)\n",
            "Collecting scikit-neuralnetwork>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/37/bfc84fc1b1bfc7364f564469cf76d90336accf16087dfd5a1bf589bd1dd9/scikit-neuralnetwork-0.7.tar.gz\n",
            "Requirement already satisfied: scikit-image>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from EmoPy) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->EmoPy) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->EmoPy) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->EmoPy) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->EmoPy) (1.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->EmoPy) (0.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (45.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (8.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->EmoPy) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (1.27.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.10.1->EmoPy) (1.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->EmoPy) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>2.1.0->EmoPy) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>2.1.0->EmoPy) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>2.1.0->EmoPy) (1.1.0)\n",
            "Requirement already satisfied: Theano>=0.8 in /usr/local/lib/python3.6/dist-packages (from scikit-neuralnetwork>=0.7->EmoPy) (1.0.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->EmoPy) (6.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->EmoPy) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->EmoPy) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->EmoPy) (2.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.1->EmoPy) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.10.1->EmoPy) (3.2.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.13.1->EmoPy) (4.4.1)\n",
            "Building wheels for collected packages: lasagne, scikit-neuralnetwork\n",
            "  Building wheel for lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lasagne: filename=Lasagne-0.1-cp36-none-any.whl size=79275 sha256=afed89cb98044c04a480417f931fa05702ff26cc66e1cdc85f2380cb490232b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/8e/31/b4cae7e5507f8582e77d7f5cf2815be8820ccacfa0519ca60c\n",
            "  Building wheel for scikit-neuralnetwork (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-neuralnetwork: filename=scikit_neuralnetwork-0.7-cp36-none-any.whl size=41700 sha256=9bd7fbccd7d6af769744fbf6c5df15f3a3fa55c54c16f3290bb27d8f3ea09707\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/2c/db/ad3c876767bfdaf955ede9b7c0315a99abb12c0bdd2a469eff\n",
            "Successfully built lasagne scikit-neuralnetwork\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.1.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.25 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, lasagne, scikit-neuralnetwork, EmoPy\n",
            "  Found existing installation: numpy 1.17.5\n",
            "    Uninstalling numpy-1.17.5:\n",
            "      Successfully uninstalled numpy-1.17.5\n",
            "Successfully installed EmoPy-0.0.5 lasagne-0.1 numpy-1.14.5 scikit-neuralnetwork-0.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbkdtuyU9zrz",
        "colab_type": "code",
        "outputId": "184a4ecb-b4ca-4add-f4bf-a9755d0bb089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Open up your google drive to save the model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_save_name = 'ConvTrainedModel.json'\n",
        "weights_save_name = 'ConvWeights.h5'\n",
        "map_save_name = 'ConvMap.json'\n",
        "graph_save_name = 'ConvModelGraph.png'\n",
        "\n",
        "filePath = F\"/content/gdrive/My Drive/Colab_Notebooks/Emotional_Recognition_Unit/TrainedModels/Conv/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er2JcfcFQb_y",
        "colab_type": "code",
        "outputId": "bf3216b0-37c0-4c01-e2b4-b54da3589fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "\n",
        "from pkg_resources import resource_filename\n",
        "\n",
        "class PlotLosses(Callback):\n",
        "\n",
        "    def __init__(self, figure_dir='output',figure_name='loss_plot.png',figure_path='output/loss_plot.png'):\n",
        "        self.figure_path = figure_path\n",
        "        self.figure_name = figure_name\n",
        "        self.figure_dir = figure_dir\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "\n",
        "        # clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        # plt.show();\n",
        "        if not os.path.isdir(self.figure_dir):\n",
        "            os.makedirs(self.figure_dir)\n",
        "        self.fig.savefig(os.path.join(self.figure_dir, self.figure_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qufjdXntPV4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, ConvLSTM2D, Conv3D, MaxPooling2D, Dropout, \\\n",
        "    MaxPooling3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Model, Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "import json\n",
        "\n",
        "#from EmoPy.src.callback import PlotLosses\n",
        "\n",
        "\n",
        "class _FERNeuralNet(object):\n",
        "    \"\"\"\n",
        "    Interface for all FER deep neural net classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emotion_map):\n",
        "        self.emotion_map = emotion_map\n",
        "        self._init_model()\n",
        "\n",
        "    def _init_model(self):\n",
        "        raise NotImplementedError(\"Class %s doesn't implement _init_model()\" % self.__class__.__name__)\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        raise NotImplementedError(\"Class %s doesn't implement fit()\" % self.__class__.__name__)\n",
        "\n",
        "    def fit_generator(self, generator, validation_data=None, epochs=50):\n",
        "        #self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
        "        self.model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "        self.model.fit_generator(generator=generator, validation_data=validation_data, epochs=epochs,\n",
        "                                 callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3), PlotLosses()])\n",
        "\n",
        "    def predict(self, images):\n",
        "        self.model.predict(images)\n",
        "\n",
        "    def save_model_graph(self, graph_filepath):\n",
        "        plot_model(self.model, to_file=graph_filepath)\n",
        "        print(\"Graph has been saved to \" + graph_filepath)\n",
        "\n",
        "    def export_model(self, model_filepath, weights_filepath, emotion_map_filepath, emotion_map):\n",
        "        self.model.save_weights(weights_filepath)\n",
        "\n",
        "        model_json_string = self.model.to_json()\n",
        "        model_json_file = open(model_filepath, 'w')\n",
        "        model_json_file.write(model_json_string)\n",
        "        model_json_file.close()\n",
        "\n",
        "        with open(emotion_map_filepath, 'w') as fp:\n",
        "            json.dump(emotion_map, fp)\n",
        "\n",
        "        print(\"Model has been saved to \" + model_filepath)\n",
        "\n",
        "\n",
        "class TransferLearningNN(_FERNeuralNet):\n",
        "    \"\"\"\n",
        "    Transfer Learning Convolutional Neural Network initialized with pretrained weights.\n",
        "    :param model_name: name of pretrained model to use for initial weights. Options: ['Xception', 'VGG16', 'VGG19', 'ResNet50', 'InceptionV3', 'InceptionResNetV2']\n",
        "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
        "    **Example**::\n",
        "        model = TransferLearningNN(model_name='inception_v3', target_labels=[0,1,2,3,4,5,6])\n",
        "        model.fit(images, labels, validation_split=0.15)\n",
        "    \"\"\"\n",
        "    _NUM_BOTTOM_LAYERS_TO_RETRAIN = 249\n",
        "\n",
        "    def __init__(self, model_name, emotion_map):\n",
        "        self.model_name = model_name\n",
        "        super().__init__(emotion_map)\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"\n",
        "        Initialize base model from Keras and add top layers to match number of training emotions labels.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        base_model = self._get_base_model()\n",
        "\n",
        "        top_layer_model = base_model.output\n",
        "        top_layer_model = GlobalAveragePooling2D()(top_layer_model)\n",
        "        top_layer_model = Dense(1024, activation='relu')(top_layer_model)\n",
        "        prediction_layer = Dense(output_dim=len(self.emotion_map.keys()), activation='softmax')(top_layer_model)\n",
        "\n",
        "        model = Model(input=base_model.input, output=prediction_layer)\n",
        "        print(model.summary())\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def _get_base_model(self):\n",
        "        \"\"\"\n",
        "        :return: base model from Keras based on user-supplied model name\n",
        "        \"\"\"\n",
        "        if self.model_name == 'inception_v3':\n",
        "            return InceptionV3(weights='imagenet', include_top=False)\n",
        "        elif self.model_name == 'xception':\n",
        "            return Xception(weights='imagenet', include_top=False)\n",
        "        elif self.model_name == 'vgg16':\n",
        "            return VGG16(weights='imagenet', include_top=False)\n",
        "        elif self.model_name == 'vgg19':\n",
        "            return VGG19(weights='imagenet', include_top=False)\n",
        "        elif self.model_name == 'resnet50':\n",
        "            return ResNet50(weights='imagenet', include_top=False)\n",
        "        else:\n",
        "            raise ValueError('Cannot find base model %s' % self.model_name)\n",
        "\n",
        "    def fit(self, features, labels, validation_split, epochs=50):\n",
        "        \"\"\"\n",
        "        Trains the neural net on the data provided.\n",
        "        :param features: Numpy array of training data.\n",
        "        :param labels: Numpy array of target (label) data.\n",
        "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
        "        :param epochs: Max number of times to train over dataset.\n",
        "        \"\"\"\n",
        "        self.model.fit(x=features, y=labels, epochs=epochs, verbose=1,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)], validation_split=validation_split,\n",
        "                       shuffle=True)\n",
        "\n",
        "        for layer in self.model.layers[:self._NUM_BOTTOM_LAYERS_TO_RETRAIN]:\n",
        "            layer.trainable = False\n",
        "        for layer in self.model.layers[self._NUM_BOTTOM_LAYERS_TO_RETRAIN:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        self.model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        self.model.fit(x=features, y=labels, epochs=50, verbose=1,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)], validation_split=validation_split,\n",
        "                       shuffle=True)\n",
        "\n",
        "class ConvolutionalLstmNN(_FERNeuralNet):\n",
        "    \"\"\"\n",
        "    Convolutional Long Short Term Memory Neural Network.\n",
        "    :param image_size: dimensions of input images\n",
        "    :param channels: number of image channels\n",
        "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
        "    :param time_delay: number of time steps for lookback\n",
        "    :param filters: number of filters/nodes per layer in CNN\n",
        "    :param kernel_size: size of sliding window for each layer of CNN\n",
        "    :param activation: name of activation function for CNN\n",
        "    :param verbose: if true, will print out extra process information\n",
        "    **Example**::\n",
        "        net = ConvolutionalLstmNN(target_dimensions=(64,64), channels=1, target_labels=[0,1,2,3,4,5,6], time_delay=3)\n",
        "        net.fit(features, labels, validation_split=0.15)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_size, channels, emotion_map, time_delay=2, filters=10, kernel_size=(4, 4),\n",
        "                 activation='sigmoid', verbose=False):\n",
        "        self.time_delay = time_delay\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.activation = activation\n",
        "        super().__init__(emotion_map)\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"\n",
        "        Composes all layers of CNN.\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation,\n",
        "                             input_shape=[self.time_delay] + list(self.image_size) + [self.channels],\n",
        "                             data_format='channels_last', return_sequences=True))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation,\n",
        "                             input_shape=(self.time_delay, self.channels) + self.image_size,\n",
        "                             data_format='channels_last', return_sequences=True))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv2D(filters=1, kernel_size=self.kernel_size, activation=\"sigmoid\", data_format=\"channels_last\"))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"sigmoid\"))\n",
        "        if self.verbose:\n",
        "            model.summary()\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, features, labels, validation_split, batch_size=10, epochs=50):\n",
        "        \"\"\"\n",
        "        Trains the neural net on the data provided.\n",
        "        :param features: Numpy array of training data.\n",
        "        :param labels: Numpy array of target (label) data.\n",
        "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
        "        :param batch_size:\n",
        "        :param epochs: number of times to train over input dataset.\n",
        "        \"\"\"\n",
        "        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
        "        self.model.fit(features, labels, batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n",
        "\n",
        "class ConvolutionalNN(_FERNeuralNet):\n",
        "    \"\"\"\n",
        "    2D Convolutional Neural Network\n",
        "    :param image_size: dimensions of input images\n",
        "    :param channels: number of image channels\n",
        "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
        "    :param filters: number of filters/nodes per layer in CNN\n",
        "    :param kernel_size: size of sliding window for each layer of CNN\n",
        "    :param activation: name of activation function for CNN\n",
        "    :param verbose: if true, will print out extra process information\n",
        "    **Example**::\n",
        "        net = ConvolutionalNN(target_dimensions=(64,64), channels=1, target_labels=[0,1,2,3,4,5,6], time_delay=3)\n",
        "        net.fit(features, labels, validation_split=0.15)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_size, channels, emotion_map, filters=10, kernel_size=(4, 4), activation='relu',\n",
        "                 verbose=False):\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.activation = activation\n",
        "        super().__init__(emotion_map)\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"\n",
        "        Composes all layers of 2D CNN.\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(input_shape=list(self.image_size) + [self.channels], filters=self.filters,\n",
        "                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(MaxPooling2D())\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(MaxPooling2D())\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"relu\"))\n",
        "        if self.verbose:\n",
        "            model.summary()\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, image_data, labels, validation_split, epochs=50):\n",
        "        \"\"\"\n",
        "        Trains the neural net on the data provided.\n",
        "        :param image_data: Numpy array of training data.\n",
        "        :param labels: Numpy array of target (label) data.\n",
        "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
        "        :param batch_size:\n",
        "        :param epochs: number of times to train over input dataset.\n",
        "        \"\"\"\n",
        "        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
        "        self.model.fit(image_data, labels, epochs=epochs, validation_split=validation_split,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n",
        "\n",
        "class ConvolutionalNNDropout(_FERNeuralNet):\n",
        "    \"\"\"\n",
        "    2D Convolutional Neural Network implementing Dropout and batch normalization\n",
        "    :param image_size: dimensions of input images\n",
        "    :param channels: number of image channels\n",
        "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
        "    :param filters: number of filters/nodes per layer in CNN\n",
        "    :param kernel_size: size of sliding window for each layer of CNN\n",
        "    :param activation: name of activation function for CNN\n",
        "    :param verbose: if true, will print out extra process information\n",
        "    **Example**::\n",
        "        net = ConvolutionalNNDropout(target_dimensions=(64,64), channels=1, target_labels=[0,1,2,3,4,5,6], time_delay=3)\n",
        "        net.fit(features, labels, validation_split=0.15)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_size, channels, emotion_map, filters=10, kernel_size=(4, 4), activation='relu',\n",
        "                 verbose=False):\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.activation = activation\n",
        "        super().__init__(emotion_map)\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"\n",
        "        Composes all layers of 2D CNN.\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(input_shape=list(self.image_size) + [self.channels], filters=self.filters,\n",
        "                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(\n",
        "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "\n",
        "\n",
        "        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"softmax\"))\n",
        "        if self.verbose:\n",
        "            model.summary()\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, image_data, labels, validation_split, epochs=50):\n",
        "        \"\"\"\n",
        "        Trains the neural net on the data provided.\n",
        "        :param image_data: Numpy array of training data.\n",
        "        :param labels: Numpy array of target (label) data.\n",
        "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
        "        :param batch_size:\n",
        "        :param epochs: number of times to train over input dataset.\n",
        "        \"\"\"\n",
        "        self.model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "        self.model.fit(image_data, labels, epochs=epochs, validation_split=validation_split,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])\n",
        "\n",
        "class TimeDelayConvNN(_FERNeuralNet):\n",
        "    \"\"\"\n",
        "    The Time-Delayed Convolutional Neural Network model is a 3D-Convolutional network that trains on 3-dimensional temporal image data. One training sample will contain n number of images from a series and its emotion label will be that of the most recent image.\n",
        "    :param image_size: dimensions of input images\n",
        "    :param time_delay: number of past time steps included in each training sample\n",
        "    :param channels: number of image channels\n",
        "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
        "    :param filters: number of filters/nodes per layer in CNN\n",
        "    :param kernel_size: size of sliding window for each layer of CNN\n",
        "    :param activation: name of activation function for CNN\n",
        "    :param verbose: if true, will print out extra process information\n",
        "    **Example**::\n",
        "        model = TimeDelayConvNN(target_dimensions={64,64), time_delay=3, channels=1, label_count=6)\n",
        "        model.fit(image_data, labels, validation_split=0.15)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_size, channels, emotion_map, time_delay, filters=32, kernel_size=(1, 4, 4),\n",
        "                 activation='relu', verbose=False):\n",
        "        self.image_size = image_size\n",
        "        self.time_delay = time_delay\n",
        "        self.channels = channels\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.activation = activation\n",
        "        super().__init__(emotion_map)\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"\n",
        "        Composes all layers of 3D CNN.\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(input_shape=[self.time_delay] + list(self.image_size) + [self.channels], filters=self.filters,\n",
        "                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(\n",
        "            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(MaxPooling3D(pool_size=(1, 2, 2), data_format='channels_last'))\n",
        "        model.add(\n",
        "            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(\n",
        "            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
        "        model.add(MaxPooling3D(pool_size=(1, 2, 2), data_format='channels_last'))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"relu\"))\n",
        "        if self.verbose:\n",
        "            model.summary()\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, image_data, labels, validation_split, epochs=50):\n",
        "        \"\"\"\n",
        "        Trains the neural net on the data provided.\n",
        "        :param image_data: Numpy array of training data.\n",
        "        :param labels: Numpy array of target (label) data.\n",
        "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
        "        :param batch_size:\n",
        "        :param epochs: number of times to train over input dataset.\n",
        "        \"\"\"\n",
        "        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
        "        self.model.fit(image_data, labels, epochs=epochs, validation_split=validation_split,\n",
        "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N41uKmbl9KtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convolutional model trainer\n",
        "import matplotlib.pyplot as plt\n",
        "from EmoPy.src.fermodel import FERModel\n",
        "from EmoPy.src.directory_data_loader import DirectoryDataLoader\n",
        "from EmoPy.src.data_generator import DataGenerator\n",
        "#from EmoPy.src.neuralnets import ConvolutionalNN\n",
        "\n",
        "from pkg_resources import resource_filename,resource_exists\n",
        "\n",
        "#train a convolutional model\n",
        "def TrainConvModel():\n",
        "  validation_split = 0.15\n",
        "\n",
        "  target_dimensions = (64, 64)\n",
        "  channels = 1\n",
        "  verbose = True\n",
        "\n",
        "  numOfEpochs = 5\n",
        "  fileBatchSize = 1\n",
        "\n",
        "  print('--------------- Convolutional Model -------------------')\n",
        "  print('Loading data...')\n",
        "  directory_path = resource_filename('EmoPy.examples','image_data/sample_image_directory')\n",
        "  data_loader = DirectoryDataLoader(datapath=directory_path, validation_split=validation_split)\n",
        "  dataset = data_loader.load_data()\n",
        "\n",
        "  if verbose:\n",
        "      dataset.print_data_details()\n",
        "\n",
        "  print('Preparing training/testing data...')\n",
        "  train_images, train_labels = dataset.get_training_data()\n",
        "  train_gen = DataGenerator().fit(train_images, train_labels)\n",
        "  test_images, test_labels = dataset.get_test_data()\n",
        "  test_gen = DataGenerator().fit(test_images, test_labels)\n",
        "\n",
        "  print('Training net...')\n",
        "  convModel = ConvolutionalNN(target_dimensions, channels, dataset.get_emotion_index_map(), verbose=True)\n",
        "  convModel.fit_generator(train_gen.generate(target_dimensions, batch_size=fileBatchSize),\n",
        "                      test_gen.generate(target_dimensions, batch_size=fileBatchSize),\n",
        "                      epochs=numOfEpochs)\n",
        "\n",
        "  # Save model configuration\n",
        "  convModel.export_model(filePath+model_save_name, filePath+weights_save_name, filePath+map_save_name, convModel.emotion_map)\n",
        "  convModel.save_model_graph(filePath+graph_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH7mnjktDxjg",
        "colab_type": "code",
        "outputId": "1496ac29-7f7a-45cf-bbfb-3ede1ac26d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TrainConvModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- Convolutional Model -------------------\n",
            "Loading data...\n",
            "\n",
            "DATASET DETAILS\n",
            "18 image samples\n",
            "15 training samples\n",
            "3 test samples\n",
            "\n",
            "Preparing training/testing data...\n",
            "Training net...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 61, 61, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 58, 58, 10)        1610      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 58, 29, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 55, 26, 10)        810       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 52, 23, 10)        1610      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 52, 11, 5)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2860)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 8583      \n",
            "=================================================================\n",
            "Total params: 12,783\n",
            "Trainable params: 12,783\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 7s 491ms/step - loss: 1.2323 - acc: 0.2667 - val_loss: 6.9721 - val_acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.1217 - acc: 0.1333 - val_loss: 6.2483 - val_acc: 0.3333\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 1.1943 - acc: 0.3333 - val_loss: 5.9471 - val_acc: 0.3333\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.1421 - acc: 0.2000 - val_loss: 5.8590 - val_acc: 0.3333\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 1.1093 - acc: 0.3333 - val_loss: 6.0952 - val_acc: 0.3333\n",
            "Model has been saved to /content/gdrive/My Drive/Colab_Notebooks/Emotional_Recognition_Unit/TrainedModels/Conv/ConvTrainedModel.json\n",
            "Graph has been saved to /content/gdrive/My Drive/Colab_Notebooks/Emotional_Recognition_Unit/TrainedModels/Conv/ConvModelGraph.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHGD2HqhgdU8",
        "colab_type": "code",
        "outputId": "7f32e749-5324-4eb8-e5dd-9c9748ad17ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "25\n",
        "26\n",
        "27\n",
        "28\n",
        "29\n",
        "30\n",
        "31\n",
        "32\n",
        "33\n",
        "34\n",
        "35\n",
        "36\n",
        "37\n",
        "38\n",
        "39\n",
        "40\n",
        "41\n",
        "42\n",
        "43\n",
        "44\n",
        "45\n",
        "46\n",
        "47\n",
        "48\n",
        "49\n",
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        " \n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later...\n",
        " \n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# MLP for Pima Indians Dataset Serialize to JSON and HDF5\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.models import model_from_json\\nimport numpy\\nimport os\\n\\n\\n# load json and create model\\njson_file = open(\\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = model_from_json(loaded_model_json)\\n# load weights into new model\\nloaded_model.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")\\n\\n# evaluate loaded model on test data\\nloaded_model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'rmsprop\\', metrics=[\\'accuracy\\'])\\nscore = loaded_model.evaluate(X, Y, verbose=0)\\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n32\\n33\\n34\\n35\\n36\\n37\\n38\\n39\\n40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n# MLP for Pima Indians Dataset Serialize to JSON and HDF5\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.models import model_from_json\\nimport numpy\\nimport os\\n# fix random seed for reproducibility\\nnumpy.random.seed(7)\\n# load pima indians dataset\\ndataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\\n# split into input (X) and output (Y) variables\\nX = dataset[:,0:8]\\nY = dataset[:,8]\\n# create model\\nmodel = Sequential()\\nmodel.add(Dense(12, input_dim=8, activation=\\'relu\\'))\\nmodel.add(Dense(8, activation=\\'relu\\'))\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\n# Compile model\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n# Fit the model\\nmodel.fit(X, Y, epochs=150, batch_size=10, verbose=0)\\n# evaluate the model\\nscores = model.evaluate(X, Y, verbose=0)\\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\\n \\n# serialize model to JSON\\nmodel_json = model.to_json()\\nwith open(\"model.json\", \"w\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nmodel.save_weights(\"model.h5\")\\nprint(\"Saved model to disk\")\\n \\n# later...\\n \\n# load json and create model\\njson_file = open(\\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = model_from_json(loaded_model_json)\\n# load weights into new model\\nloaded_model.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")\\n \\n# evaluate loaded model on test data\\nloaded_model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'rmsprop\\', metrics=[\\'accuracy\\'])\\nscore = loaded_model.evaluate(X, Y, verbose=0)\\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}